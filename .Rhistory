for (i in 1:1327) { t <- rN[[i]][[2]]
if ( t[1]$text == "21231") cnt <- cnt + 1 }
t
t[1]
t[1]$text
t[1]$text == 21206
is.atomic(t[1]$text)
t[1]$text[1]
t[1]$text[[1]]
t[[1]]
is.atomic(t[[1]])
t[[1]][[1]]
as.atomic(t[[1]])
t
t[[1]]
xmlParse(t)
xmlAttrs(t)
xmlAttrs(rN)
xmlAttrs(rN[["zipcode"]])
head(data)
data
xmlAttrs(xmlRoot(data))
xmlAttrs(xmlRoot(data)[["zipcode"]])
xmlSApply(rN[[1]], xmlName)
xmlApply(rN[[1]], xmlName)
xmlApply(rN[[1]], xmlAttrs)
xmlApply(rN[[1]], xmlName)
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv", destfile="data\\Q1.5.csv")
library(data.table)
library(table)
library(data)
fread("data\\Q1.5.csv")
require(data.table)
require(data)
install.packages("data.table")
DT <- fread("Q1.5.csv")
library("data.table")
DT <- fread("Q1.5.csv")
DT <- fread("data\\Q1.5.csv")
head(DT)
tapply(DT$pwgtp15,DT$SEX,mean)
s <- proc.time() : tapply(DT$pwgtp15,DT$SEX,mean) : proc.time() - s
s <- proc.time() ; tapply(DT$pwgtp15,DT$SEX,mean) ; proc.time() - s
s <- proc.time() ; DT[,mean(pwgtp15),by=SEX] ; proc.time() - s
s <- proc.time() ; sapply(split(DT$pwgtp15,DT$SEX),mean) ; proc.time() - s
test.r
source(test.r)
source("test.r")
source("test.r")
source("test.r")
source("test.r")
source("test.r")
source("test.r")
source("test.r")
source("test.r")
source("test.r")
rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2]
rowMeans(DT)[DT$SEX==1]
rowMeans(DT)
DT$pwgtp15
mean(DT$pwgtp15,by=DT$SEX)
source("test.r")
source("test.r")
source("test.r")
tables()
source("test.r")
source("test.r")
source("test.r")
source("test.r")
source("test.r")
tapply(DT$pwgtp15,DT$SEX,mean)
DT[,mean(pwgtp15),by=SEX]
sapply(split(DT$pwgtp15,DT$SEX),mean)
mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)
mean(DT$pwgtp15,by=DT$SEX)
source("test.r")
data <- read.csv("data\\Q1.1.csv")
head(data)
data$FES
library(swirl)
install_from_swirl("Getting and Cleaning Data")
library(swirl)
install_from_swirl("Getting and Cleaning Data")
swirl
swirl()
mydf <- read.csv(path2csv, stringsAsFactors = FALSE)
dim(mydf)
head(mydf)
library(dplyr)
packageVersion("dplyr")
cran <- tbl_df(mydf)
rm("mydf")
cran
?select
select(cran, ip_id, package, country)
5:20
select(cran,r_arch:country)
select(cran,country:r_arch)
cran
select(cran, -time)
-5:20
-(5:20)
select(cran,-(x:size))
play
select(cran, -(x:size))
select(cran, -(X:size))
filter(cran,package=="swirl")
filter(cran, r_version == "3.1.1", country == "US")
?Comparison
filter(cran, r_version <= "3.0.2", country == "IN")
filter(cran, country == "US" | country == "IN")
filter(cran, size > 100500, r_os == "linux-gnu")
is.na(c(3, 5, NA, 10))
!is.na(c(3, 5, NA, 10))
filter(cran, !is.na(r_version))
cran2 <- select(cran, size:ip_id)
arrange(cran2, ip_id)
arrange(cran2, desc(ip_id))
arrange(cran2, package, ip_id)
arrange(cran2, country, r_version, desc(ip_id))
arrange(cran2, country, desc(r_version), ip_id)
cran3 <- select(cran, ip_id, package, size)
cran3
mutate(cran3, size_mb = size / 2^20)
mutate(cran3, size_mb = size / 2^20, size_gb = size_mb / 2^10)
mutate(cran3, correct_size = size + 1000)
summarize(cran, avg_bytes = mean(size))
library(dplyr)
cran <- tabl_df(mydf)
cran <- tbl_df(mydf)
rm("mydf")
cran
?group_by
by_package <- group_by(cran, package)
by_package
summarize(by_package, mean(size))
submit()
pack_sum
quantile(pack_sum$count, probs = 0.99)
top_counts <- filter(pack_sum, count > 679)
top_counts
Viem(top_counts)
View(top_counts)
top_counts_sorted <- arrange(top_counts, desc(count))
View(top_counts_sorted)
quantile(pack_sum$unique, probs = 0.99)
top_unique <- filter(pack_sum, unique > 465)
view(top_unique)
View(top_unique)
top_unique_sorted <- arrange(top_unique, desc(count))
top_unique_sorted <- arrange(top_unique, desc(unique))
View(top_unique_sorted)
submit()
submit()
submit()
View(result3)
submit()
submit()
submit()
submit()
library(swirl)
swirl()
library(tidyr)
students
?gather
gather(students, sex, count, -grade)
students2
res <- gather(students2, sex_class, count, -grade)
res
?separate
separate(res, col=sex_class, into=c("sex", "class"))
submit()
submit()
students3
submit()
submit()
?spread
?spread
submit()
submit()
submit()
reset()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
extract_numeric("class5")
submit()
submit()
students4
submit()
submit()
?unique
submit()
submit()
passed
failed
passed <- mutate(passed, status="passed")
failed <- mutate(failed, status="failed")
?bind_rows
bind_rows(passed,failed)
sat
?selet
?select
submit()
?group_by
submit()
Sys.getlocale("LC_TIME")
?getlocale
?Sys.getlocale
library(lubridate)
help(package = lubridate)
this_day <- today()
this_day
month(this_day)
wday(this_day)
wday(this_day, label=TRUE)
this_moment <- now()
this_moment
hour(this_moment)
my_date<-ymd("1989-05-17")
my_date
class(my_date)
ymd("1989 May 17")
mdy("March 12, 1975")
dmy(25081985)
ymd("192012")
ymd("1920/1/2")
dt1
ymd_hms(dt1)
hms("03:22:14")
dt2
ymd(dt2)
update(this_moment, hours = 8, minutes = 34, seconds = 55)
this_moment
now
now()
this_moment <- update(this_moment, hours =16, minutes=28, seconds=28)
this_moment
?now
nyc <- now(tzone="America/New_York")
nyc
depart <- nyc + days(2)
depart
depart <- update(depart, hours = 17, minutes = 34)
depart
arrive <- depart + hours(15) + minutes(50)
with_tz(arrive, tzone="Hong Kong")
?with_tz
arrive <- with_tz(arrive, tzone="Asia/Hong Kong")
arrive <- with_tz(arrive, "Asia/Hong Kong")
arrive <- with_tz(arrive, "Asia/Hong_Kong")
arrive
last_time <- mdy("June 17, 2008", tz="Singapore")
last_time
?new_interval
how_long <- new_interval(last_time, arrive)
as.period(how_long)
stopwatch()
acs <- read.csv("data/getdata-data-ss06pid.csv")
library("sqldf")
package("sqldf")
require("sqldf")
library("sqldf")
install.package("sqldf")
install.packages("sqldf")
library("sqldf")
sqldf("select * from acs where AGEP < 50")
sqldf("select pwgtp1 from acs")
sqldf("select * from acs")
sqldf("select pwgtp1 from acs where AGEP < 50")
v <- sqldf("select pwgtp1 from acs where AGEP < 50")
head(v)
head(acs$AGEP)
head(acs$pwgtp1)
unique(acs$AGEP)
sqldf("select unique AGEP from acs")
sqldf("select distinct AGEP from acs")
con <- url("http://biostat.jhsph.edu/~jleek/contact.html")
htmlCode <- readlines(con)
htmlCode <- readLines(con)
close(con)
htmlCode
htmlCode[10]
htmlCode[20]
htmlCode[30]
htmlCode[100]
nchar(htmlCode[10])
nchar(htmlCode[20])
nchar(htmlCode[30])
nchar(htmlCode[100])
val <- read.table("data/getdata-wksst8110.for", col.names="onecolperline", skip=4)
val <- read.table("data/getdata-wksst8110.for", sep = "^", col.names="onecolperline", skip=4)
head(val)
library(sqldf)
val[1]
val[,1]
head(val)
substr(val[1], 1, 1)
substr(val[1], 1, 10)
substr(val[1], 1, 80)
val <- read.table("data/getdata-wksst8110.for", sep = "^", skip = 4)
head(val)
tail(val)
str(val)
val$v1
val[1]
ncols(val)
ncol(val)
nrow(val)
val[1,1]
head(val)
row(val,1)
col(val,1)
object.size(val)
str(val)
val <- read.csv("getdata-wksst8110.for", sep = "^")
val <- read.csv("data/getdata-wksst8110.for", sep = "^")
str(val)
val[1]
head(val,8)
newval <- val[3:1256]
val(1)
val[1,1]
val <- readChar("data/getdata-wksst8110.for")
readLines("data/getdata-wksst8110.for")
val <- readLines("data/getdata-wksst8110.for")
val[1]
val[2]
val[3]
val[4]
val[5]
val2 <- val[5:1257]
val2[1]
substr(val2[1],29,33)
substr(val2[1],29,32)
val3 <- substr(val2,29,32)
val3
sum(val3)
sum(as.numeric(val3))
head(val3)
tail(val3)
count(val3)
length(val3)
32401.6+25.1
library(dplyer)
install.package(dplyer)
install.packages(dplyer)
install.packages("dplyer")
library(dplyer)
library(dfsql)
library(dmsql)
jpeg("data/getdata-jeff.jpg")
pic <- jpeg("data/getdata-jeff.jpg")
pic <- jpeg("data/jeff.jpg")
str(pic)
pic <- jpeg(filename ="data/jeff.jpg")
install.packages(jpeg)
install.packages("jpeg")
library(jpeg)
img <- readJPEG("data/jeff.jpg", native=TRUE)
str(img)
quantile(img, probs = c(.3,.8))
gdr <- read.csv("data/GDP.csv")
gdp <- gdr
delete(gdr)
remove(gdr)
edu <- read.csv("data/EDSTATS_Country.csv")
names(gdp)
names(edu)
head(gdp,2)
gdp <- read.csv("data/GDP.csv", skip = 5)
head(gdp)
gdp <- read.csv("data/GDP.csv", skip = 4)
head(gdp)
head(edu)
head(gdp)
gdp <- read.csv("data/GDP.csv", skip = 4, col.names = c("CountryCode","Ranking","Blank","Economy","GDP"))
gdp <- read.csv("data/GDP.csv", skip = 4, col.names = c("CountryCode","Ranking","Blank","Economy","GDP","J1","J2","J3,"J4""))
gdp <- read.csv("data/GDP.csv", skip = 4, col.names = c("CountryCode","Ranking","Blank","Economy","GDP","J1","J2","J3,"J4"))
gdp <- read.csv("data/GDP.csv", skip = 4, col.names = c("CountryCode","Ranking","Blank","Economy","GDP","J1","J2","J3,"J4"))
gdp <- read.csv("data/GDP.csv", skip = 4, col.names = c("CountryCode","Ranking","Blank","Economy","GDP","1","2","3","4"))
gdp <- read.csv("data/GDP.csv", skip = 4, col.names = c("CountryCode","Ranking","Blank","Economy","GDP","1","2","3","4","5"))
head(gdp)
library(dplyr)
head(gdp[,CountryCode:GDP)]
head(gdp[,CountryCode:GDP])
head(gdp[,"CountryCode":"GDP"])
head(gdp[,1:4])
gdp <- gdp[,1:4]
head(gdp)
head(edu,1)
head(gdp)
head(gdp[,-3])
gdp <- head(gdp[,-3])
gdp
head(merge(gdp, edu, by.x = "CountryCode", by.y = "CountryCode"))
ans <- merge(gdp, edu, by.x = "CountryCode", by.y = "CountryCode")
str(ans)
ans
nrow(ans)
ncol(ans)
ans <- merge(edu, gdp, by.x = "CountryCode", by.y = "CountryCode")
str(ans)
nrow(gdp)
nrow(edu)
gdp <- read.csv("data/GDP.csv", skip = 4, col.names = c("CountryCode","Ranking","Blank","Economy","GDP","1","2","3","4","5"))
head(gdp)
gdp <- gdp[,1:4]
gdp <- gdp[,-3]
head(gdp)
nrow(gdp)
ans <- merge(gdp, edu, by.x = "CountryCode", by.y = "CountryCode")
nrow(ans)
head(ans,1)
str(ans)
is.na(ans$CountryCode)
head(ans[,1:5])
head(sort(ans,ans$Ranking))
sort(ans$Ranking)
gdp <- read.csv("data/GDP.csv", skip = 4, col.names = c("CountryCode","Ranking","Blank","Economy","GDP","1","2","3","4","5"), nrows=190)
tail(gdp)
gdp <- gdp[,1:4]
gdp <- gdp[,-3]
ans <- merge(gdp, edu, by.x = "CountryCode", by.y = "CountryCode")
nrow(ans)
head(ans)
ans[1:5,1:5]
head(arrange(ans,desc(Ranking)))
head(arrange(ans,desc(Ranking))[,5])
sans <- arrange(ans, desc(Ranking))
sans[1:5,1:5]
sans[1:13,1:5]
sans[185:189,1:5]
h <- filter(sans, Income.Group == "High income: OECD")
nrow(h)
mean(h$Ranking)
h2 <- filter(sans, Income.Group == "High income: nonOECD")
nrow(h2)
mean(h2$Ranking)
c <- cut(sans, 5)
c <- cut(sans$Ranking, 5)
str(c)
head(c)
nrow(sans)
189 / 5
temp <- head(sans,38)
filter(temp, Income.Group="Lower middle income")
filter(temp, Income.Group=="Lower middle income")
nrow(filter(temp, Income.Group=="Lower middle income"))
temp <- tail(sans,38)
nrow(filter(temp, Income.Group=="Lower middle income"))
q41 <- readcsv("ss06hid.csv")
q41 <- read.csv("data/ss06hid.csv")
str(q41)
names(q41)
strsplit(names(q41), "wgtp")
strsplit(names(q41), "wgtp")[[123]]
head(gdp)
grep("^United"gdp$Economy)
grep("^United",gdp$Economy)
grep("United",gdp$Economy)
grep("[Uu]nited",gdp$Economy)
str(ans)
ans[Special.Notes="^Fiscal year end",]
filter(ans, Special.Notes="^Fiscal year end")
filter(ans, Special.Notes=="^Fiscal year end")
filter(ans, Special.Notes=="Fiscal year end")
grepl("^Fiscal year end", ans$Special.Notes)
filter(ans, grepl("^Fiscal year end", ans$Special.Notes))
newans <- filter(ans, grepl("^Fiscal year end", ans$Special.Notes))
nrow(newans)
newans$Special.Notes
grep("June", newans$Special.Notes)
length(grep("June", newans$Special.Notes))
library(quantmod)
install.packages("quantmod")
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
str(sampleTimes)
head(sampleTimes)
length(SampleTimes)
length(sampleTimes)
length(grep("^2012", sampleTimes))
ssamp <- grepl("^2012", sampleTimes)
ssamp <- sampleTimes[grepl("^2012", sampleTimes),]
ssamp <- sampleTimes[grepl("^2012", sampleTimes)]
nrow(ssamp)
head(ssamp)
length(ssamp)
ssamp[1]
wday(as.Date(ssamp[1]))
wsamp <- wday(as.Date(ssamp))
length(ssamp)
length(wsamp == 2)
length(wsamp)
head(wsamp)
head(wsamp == 2)
lans <- wsamp == 2
sum(wsamp)
sum(lans)
setwd("C:/DataScience/Getting_and_Cleaning_Data/project")
setwd("~/")
getwd
getwd()
setwd("C:/DataScience/Getting_and_Cleaning_Data/project")
